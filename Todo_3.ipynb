{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CRUD operations\n",
    "\n",
    "Create a new db name Todo and a new collection named \"CRUD_exercise\" and do the following:\n",
    "\n",
    "**TODO 1**: Take the dict created in the TODO 4 in chapter II and save it in the collection \"CRUD_exercise\".\n",
    "\n",
    "**TODO 2**: Insert 3 documents with key = x and values = 1, delete one of them. Which one is deleted first ? the most recent or oldest one ? increment the value of x to 4.\n",
    "\n",
    "**TODO 3**: Insert the dict created in the TODO 6 Chapter II in the example collection.\n",
    "\n",
    "**TODO 4**: Get documents where authors key exist in the collection \"CRUD_exercise\".\n",
    "\n",
    "**TODO 5**: Change the documents where x = 4 to x = 1.\n",
    "\n",
    "**TODO 6**: Find documents where author is not_mike and set author as real_mike.\n",
    "\n",
    "**TODO 7**: Delete documents where author is real_mike.\n",
    "\n",
    "#### Managing DB\n",
    "\n",
    "**TODO 8**: create a collection named \"CRUD_exercise_benchmark\" with 500k observations, ids increment of 2 (sequence:0,2,4,6,...1M). Give a random np.array with a key named \"values\" and use the insert_many. Then create an index on the id and benchmark queries before and after indexing. Did the index help ?\n",
    "\n",
    "**TODO 9**: create a random collection in a random db and put the new collection in the tutorial DB\n",
    "\n",
    "**TODO 10**: What is the difference between an inner join and an outer join ? Is the query seen during course an inner or outer join ? Play with the query to show all the joins.\n",
    "\n",
    "#### Real world problems\n",
    "\n",
    "**TODO 11**:  Use the oaipmh and api code get papers \"econ\" categories. Insert them in MongoDB. Import only the first 200. How is it sorted ? How can you define your own sort()? Query papers to get papers after 2021, which have 3 authors and with domain \"econ\".\n",
    "\n",
    "**TODO 12**: Do the same as TODO 8 but with the connection to the cluster. Then check the metrics and take screenshot of opcounters, logical size and connections.\n",
    "\n",
    "**TODO 13**: Download a random image and store it in a collection.\n",
    "\n",
    "**TODO 14**: Try to store a pandas dataframe in mongoDB (array with rownames, array with colnames and matrix with values)\n",
    "\n",
    "**TODO 15**: Insert the movie_review.tsv data into mongodb. Then query it to find the number of review that are positive and negative review. Fetch the docs which have \"unexpected\" in their review, how many are they ? Think of a clever way to count the number of words in the review using MongoDB (hint: Transform the review text before the insert in MongoDB) and create a density of number of words per review.\n",
    "\n",
    "**TODO 16**: Download a [sound sample](https://freesound.org/browse/). Try to store it in MongoDB \n",
    "\n",
    "**TODO 17**: Create a collection with 30M observation with a single key : \"year\" which is a random value between 2000-2020. Get documents with year = 2000. Does using an index helps ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import tqdm\n",
    "import numpy as np\n",
    "\n",
    "client = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "\n",
    "db = client[\"Todo\"]\n",
    "collection = db[\"CRUD_exercise\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#1\n",
    "lecun_paper = {\n",
    "    \"title\": \"Deep Learning\",\n",
    "    \"authors\": {\n",
    "        \"Yann LeCun\": {\"affiliations\": [\"Facebook AI Research\", \"New York University\"]},\n",
    "        \"Yoshua Bengio\": {\"affiliations\": [\"Department of Computer Science and Operations Research Université de Montréal\"]},\n",
    "        \"Geoffrey Hinton\": {\"affiliations\": [\"Google\", \"Department of Computer Science, University of Toronto\"]}\n",
    "    }\n",
    "}\n",
    "goodfellow_paper = {\n",
    "    \"title\": \"Generative Adversarial Nets\",\n",
    "    \"authors\": {\n",
    "        \"Ian Goodfellow\": {\"affiliations\": [\"Universite de Montreal\"]},\n",
    "        \"Jean Pouget-Abadie\": {\"affiliations\": [\"Ecole Polytechnique\"]},\n",
    "        \"Mehdi Mirza\": {\"affiliations\": [\"Université de Montréal\"]},\n",
    "        \"Bing Xu\": {\"affiliations\": [\"Université de Montréal\"]},\n",
    "        \"David Warde-Farley\": {\"affiliations\": [\"Université de Montréal\"]},\n",
    "        \"Sherjil Ozair\": {\"affiliations\": [\"Indian Institute of Technology Delhi\"]},\n",
    "        \"Aaron Courville\": {\"affiliations\": [\"Université de Montréal\"]},\n",
    "        \"Yoshua Bengio\": {\"affiliations\": [\"CIFAR Senior Fellow\"]}\n",
    "    }\n",
    "}\n",
    "papers_dict = {\n",
    "    \"LeCun et al.\": lecun_paper,\n",
    "    \"Goodfellow et al.\": goodfellow_paper\n",
    "}\n",
    "\n",
    "collection.insert_one(papers_dict)\n",
    "\n",
    "#2\n",
    "doc1 = {\"x\": 1, \"value\": 1}\n",
    "doc2 = {\"x\": 1, \"value\": 1}\n",
    "doc3 = {\"x\": 1, \"value\": 1}\n",
    "\n",
    "collection.insert_one(doc1)\n",
    "collection.insert_one(doc2)\n",
    "collection.insert_one(doc3)\n",
    "\n",
    "collection.delete_one({\"x\": 1})\n",
    "\n",
    "collection.update_many({\"x\": 1}, {\"$set\": {\"x\": 4}})\n",
    "\n",
    "#3\n",
    "\n",
    "import lxml.etree\n",
    "\n",
    "xml_file2 = \"/Users/lyna/Documents/GitHub/NoSQL/data/Chap2/xml_file2.nxml\"\n",
    "root = lxml.etree.parse(xml_file2)\n",
    "\n",
    "date = root.xpath(\"//date//text()\")\n",
    "hour = root.xpath(\"//hour//text()\")\n",
    "to = root.xpath(\"//to//text()\")\n",
    "from_ = root.xpath(\"//from//text()\")\n",
    "body = root.xpath(\"//body//text()\")\n",
    "\n",
    "info_dict = {\n",
    "    \"date\": date,\n",
    "    \"hour\": hour,\n",
    "    \"to\": to,\n",
    "    \"from\": from_,\n",
    "    \"body\": body\n",
    "}\n",
    "collection.insert_one(info_dict)\n",
    "\n",
    "#4\n",
    "\n",
    "docs = collection.find({\"authors\":{\"$exists\":1}})\n",
    "list(docs)\n",
    "\n",
    "#5\n",
    "collection.update_many({\"x\": 4}, {\"$set\": {\"x\": 1}})\n",
    "\n",
    "#6\n",
    "collection.update_many({\"author\": \"not_mike\"}, {\"$set\": {\"author\": \"real_mike\"}})\n",
    "\n",
    "#7\n",
    "collection.delete_many({\"author\": \"real_mike\"})\n",
    "\n",
    "#8\n",
    "import pymongo\n",
    "client = pymongo.MongoClient('localhost', 27017)\n",
    "mydb = client[\"Todo\"]\n",
    "collection = mydb[\"CRUD_exercise_benchmark\"]\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "values = np.random.rand(500000, 4)\n",
    "docs = [{\"id\": i, \"values\": values[i//2].tolist()} for i in range(0, 1000000, 2)]\n",
    "\n",
    "collection.insert_many(docs)\n",
    "\n",
    "import time\n",
    "\n",
    "# No index\n",
    "start_time = time.time()\n",
    "docs = collection.find({\"id\": 100000})\n",
    "end_time = time.time()\n",
    "print(\"Temps sans index: \", end_time - start_time)\n",
    "\n",
    "# Index\n",
    "start_time = time.time()\n",
    "docs = collection.find({\"id\": 100000}).hint(\"id_1\")\n",
    "end_time = time.time()\n",
    "print(\"Temps avec index: \", end_time - start_time)\n",
    "\n",
    "#9\n",
    "import pymongo\n",
    "client = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "random_db = client[\"random_db\"]\n",
    "random_collection = random_db[\"random_collection\"]\n",
    "\n",
    "doc = {\"key\": \"value\"}\n",
    "random_collection.insert_one(doc)\n",
    "\n",
    "tutorial_db = client[\"tutorial\"]\n",
    "tutorial_collection = tutorial_db[\"tutorial_collection\"]\n",
    "tutorial_collection.insert_many(random_collection.find())\n",
    "\n",
    "#10\n",
    "# Inner join returns only the matching documents from both collections whereas outer join returns all documents \n",
    "# from both collections, including non-matching documents as null. The query seen during the course was an inner join.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#11\n",
    "\n",
    "\n",
    "#12\n",
    "\n",
    "\n",
    "#13\n",
    "\n",
    "\n",
    "#14\n",
    "\n",
    "\n",
    "#15\n",
    "\n",
    "\n",
    "#16\n",
    "\n",
    "\n",
    "#17\n",
    "\n",
    "from pymongo import MongoClient\n",
    "from random import randint\n",
    "\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client['Todo']\n",
    "collection = db['year']\n",
    "\n",
    "batch_size = 10000\n",
    "total_records = 30000000\n",
    "records = []\n",
    "\n",
    "for i in range(total_records):\n",
    "    year = randint(2000, 2020)\n",
    "    record = {'year': year}\n",
    "    records.append(record)\n",
    "    if len(records) == batch_size:\n",
    "        collection.insert_many(records)\n",
    "        records = []\n",
    "\n",
    "if records:\n",
    "    collection.insert_many(records)\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "docs = collection.count_documents({\"year\": 2000})\n",
    "end_time = time.time()\n",
    "print('Nombre de documents avec une année égale à 2000 :', docs)\n",
    "print(\"Temps sans index: \", end_time - start_time)\n",
    "\n",
    "collection.create_index([(\"year\", 1)])\n",
    "start_time = time.time()\n",
    "docs = collection.count_documents({\"year\": 2000})\n",
    "end_time = time.time()\n",
    "print('Nombre de documents avec une année égale à 2000 :', docs)\n",
    "print(\"Temps avec index: \", end_time - start_time)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
